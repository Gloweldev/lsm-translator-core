# LSM-Core v2 - DocumentaciÃ³n de Cambios

**Fecha:** 2025-12-23  
**VersiÃ³n:** 2.0  
**Accuracy:** 97.9%

---

## ğŸ“Š Resumen de Resultados

| MÃ©trica | v1 | v2 |
|---------|----|----|
| Val Accuracy | ~50% | **97.9%** |
| Precision (macro) | N/A | 98% |
| Recall (macro) | N/A | 99% |

---

## ğŸ§  Cambios en el Transformer

### Archivo: `src/models/transformer.py`

#### 1. Feature-Weighted Embedding
Nuevo mÃ³dulo que prioriza regiones del cuerpo:

```python
# Pesos por regiÃ³n de keypoints
Cuerpo (0-16):      Ã— 1.0  (normal)
Pies (17-22):       Ã— 0.3  (poco relevante)
Cara (23-90):       Ã— 0.1  (ignorar)
Mano izq (91-111):  Ã— 2.5  (muy importante)
Mano der (112-132): Ã— 2.5  (muy importante)
```

Los pesos son **aprendibles** durante el entrenamiento.

#### 2. Arquitectura Mejorada
- **GELU** en lugar de ReLU (mejor gradientes)
- **Pre-LN** (LayerNorm antes de attention, mÃ¡s estable)
- **3 capas** de Transformer (antes 2)
- **LayerNorm adicional** en clasificador

#### 3. RegularizaciÃ³n
- Dropout aumentado en clasificador (Ã— 1.5)
- LayerNorm en embedding

---

## ğŸ“ˆ Cambios en Entrenamiento

### Archivo: `src/training/train.py`

#### 1. Anti-Overfitting

| TÃ©cnica | Valor | PropÃ³sito |
|---------|-------|-----------|
| Label Smoothing | 0.1 | Previene sobreconfianza |
| Dropout | 0.4 | RegularizaciÃ³n |
| Weight Decay | 1e-4 | L2 regularization |
| Early Stopping | patience=20 | Detiene si no mejora |

#### 2. Balanceo de Clases
**WeightedRandomSampler** para oversampling:
- Clases minoritarias (b, c) se muestrean mÃ¡s frecuentemente
- Elimina sesgo hacia "nada" (clase mayoritaria)

#### 3. Data Augmentation
```python
# Aplicado solo en entrenamiento
- Ruido gaussiano (Ïƒ=0.02)
- Escalado temporal (0.8Ã— - 1.2Ã—)
- Dropout de frames (10%)
```

#### 4. HiperparÃ¡metros Optimizados
```python
epochs: 150
batch_size: 32
learning_rate: 3e-4
n_layers: 3
dropout: 0.4
```

---

## ğŸ”§ Cambios en Inferencia

### Archivos: `src/inference/ipad_demo.py`, `video_demo.py`

#### Carga DinÃ¡mica de ConfiguraciÃ³n
El modelo ahora lee la configuraciÃ³n del checkpoint:

```python
checkpoint = torch.load(model_path)
config = checkpoint.get('config', {})

model = LSMTransformer(
    input_dim=config.get('input_dim', INPUT_DIM),
    num_classes=config.get('num_classes', 5),
    d_model=config.get('d_model', 128),
    num_layers=config.get('n_layers', 3),
    ...
)
```

Esto garantiza compatibilidad con cualquier versiÃ³n del modelo.

---

## ğŸ“ Estructura de Archivos

```
src/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ transformer.py      # Transformer v2 con Feature Weights
â”œâ”€â”€ training/
â”‚   â””â”€â”€ train.py            # Entrenamiento con oversampling
â”œâ”€â”€ inference/
â”‚   â”œâ”€â”€ ipad_demo.py        # Demo tiempo real
â”‚   â””â”€â”€ video_demo.py       # ValidaciÃ³n con videos
â””â”€â”€ extraction/
    â””â”€â”€ preprocessor.py     # Pipeline RTMPose â†’ .npy
```

---

## ğŸš€ Uso

### Entrenar
```bash
python -m src.training.train
```

### Validar con videos
```bash
python -m src.inference.video_demo
```

### Inferencia en tiempo real
```bash
python -m src.inference.ipad_demo
```

---

## ğŸ“Š Artefactos Generados

| Archivo | DescripciÃ³n |
|---------|-------------|
| `experiments/mlruns/best_model.pth` | Modelo entrenado |
| `experiments/mlruns/confusion_matrix.png` | Matriz de confusiÃ³n |
| `experiments/mlruns/training_curves.png` | Curvas loss/accuracy |
| `experiments/mlruns/mlflow.db` | Base de datos MLflow |

---

## ğŸ”® PrÃ³ximos Pasos Sugeridos

1. **MÃ¡s datos** - Agregar mÃ¡s videos de clases minoritarias
2. **MÃ¡s clases** - Expandir vocabulario de seÃ±as
3. **Exportar modelo** - ONNX para producciÃ³n
4. **API REST** - Servir modelo en servidor
